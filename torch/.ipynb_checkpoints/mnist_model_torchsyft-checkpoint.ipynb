{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Save Model\n",
    "\n",
    "https://blog.openmined.org/upgrade-to-federated-learning-in-10-lines/\n",
    "\n",
    "https://towardsdatascience.com/how-to-train-an-image-classifier-in-pytorch-and-use-it-to-perform-basic-inference-on-single-images-99465a1e9bf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T21:56:21.384561Z",
     "start_time": "2019-06-30T21:56:18.727268Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0630 17:56:21.193834 140140091848512 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/gordon/anaconda3/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
      "W0630 17:56:21.211434 140140091848512 deprecation_wrapper.py:119] From /home/gordon/anaconda3/lib/python3.6/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import syft as sy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_syft as ts # Helper functions\n",
    "import torch.onnx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T13:33:06.448509Z",
     "start_time": "2019-06-30T13:19:52.187701Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gordon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0630 09:19:55.174320 140167981172544 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/gordon/anaconda3/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
      "W0630 09:19:55.190243 140167981172544 deprecation_wrapper.py:119] From /home/gordon/anaconda3/lib/python3.6/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/gordon/workspace/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:00, 17220574.30it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/gordon/workspace/data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 1060174.90it/s]\n",
      "1654784it [00:00, 12439497.07it/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/gordon/workspace/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/gordon/workspace/data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/gordon/workspace/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/gordon/workspace/data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8192it [00:00, 459932.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/gordon/workspace/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /home/gordon/workspace/data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.305134\n",
      "Train Epoch: 1 [640/60032 (1%)]\tLoss: 2.273475\n",
      "Train Epoch: 1 [1280/60032 (2%)]\tLoss: 2.216174\n",
      "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.156802\n",
      "Train Epoch: 1 [2560/60032 (4%)]\tLoss: 2.139428\n",
      "Train Epoch: 1 [3200/60032 (5%)]\tLoss: 2.053080\n",
      "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.896611\n",
      "Train Epoch: 1 [4480/60032 (7%)]\tLoss: 1.917295\n",
      "Train Epoch: 1 [5120/60032 (9%)]\tLoss: 1.655166\n",
      "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 1.440409\n",
      "Train Epoch: 1 [6400/60032 (11%)]\tLoss: 1.231397\n",
      "Train Epoch: 1 [7040/60032 (12%)]\tLoss: 0.983658\n",
      "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.867280\n",
      "Train Epoch: 1 [8320/60032 (14%)]\tLoss: 0.890855\n",
      "Train Epoch: 1 [8960/60032 (15%)]\tLoss: 0.861959\n",
      "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.654403\n",
      "Train Epoch: 1 [10240/60032 (17%)]\tLoss: 0.587101\n",
      "Train Epoch: 1 [10880/60032 (18%)]\tLoss: 0.693248\n",
      "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.593181\n",
      "Train Epoch: 1 [12160/60032 (20%)]\tLoss: 0.531715\n",
      "Train Epoch: 1 [12800/60032 (21%)]\tLoss: 0.399852\n",
      "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.455805\n",
      "Train Epoch: 1 [14080/60032 (23%)]\tLoss: 0.438753\n",
      "Train Epoch: 1 [14720/60032 (25%)]\tLoss: 0.397977\n",
      "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.370984\n",
      "Train Epoch: 1 [16000/60032 (27%)]\tLoss: 0.289185\n",
      "Train Epoch: 1 [16640/60032 (28%)]\tLoss: 0.416432\n",
      "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.304448\n",
      "Train Epoch: 1 [17920/60032 (30%)]\tLoss: 0.367577\n",
      "Train Epoch: 1 [18560/60032 (31%)]\tLoss: 0.386742\n",
      "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.313773\n",
      "Train Epoch: 1 [19840/60032 (33%)]\tLoss: 0.238597\n",
      "Train Epoch: 1 [20480/60032 (34%)]\tLoss: 0.535023\n",
      "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.369549\n",
      "Train Epoch: 1 [21760/60032 (36%)]\tLoss: 0.465195\n",
      "Train Epoch: 1 [22400/60032 (37%)]\tLoss: 0.279580\n",
      "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.237638\n",
      "Train Epoch: 1 [23680/60032 (39%)]\tLoss: 0.182913\n",
      "Train Epoch: 1 [24320/60032 (41%)]\tLoss: 0.322589\n",
      "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.187239\n",
      "Train Epoch: 1 [25600/60032 (43%)]\tLoss: 0.286552\n",
      "Train Epoch: 1 [26240/60032 (44%)]\tLoss: 0.366184\n",
      "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.523312\n",
      "Train Epoch: 1 [27520/60032 (46%)]\tLoss: 0.147619\n",
      "Train Epoch: 1 [28160/60032 (47%)]\tLoss: 0.130835\n",
      "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.224522\n",
      "Train Epoch: 1 [29440/60032 (49%)]\tLoss: 0.273283\n",
      "Train Epoch: 1 [30080/60032 (50%)]\tLoss: 0.215146\n",
      "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.143744\n",
      "Train Epoch: 1 [31360/60032 (52%)]\tLoss: 0.291410\n",
      "Train Epoch: 1 [32000/60032 (53%)]\tLoss: 0.230331\n",
      "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.268117\n",
      "Train Epoch: 1 [33280/60032 (55%)]\tLoss: 0.204275\n",
      "Train Epoch: 1 [33920/60032 (57%)]\tLoss: 0.147346\n",
      "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.186946\n",
      "Train Epoch: 1 [35200/60032 (59%)]\tLoss: 0.172885\n",
      "Train Epoch: 1 [35840/60032 (60%)]\tLoss: 0.479915\n",
      "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.304642\n",
      "Train Epoch: 1 [37120/60032 (62%)]\tLoss: 0.243473\n",
      "Train Epoch: 1 [37760/60032 (63%)]\tLoss: 0.263584\n",
      "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.240036\n",
      "Train Epoch: 1 [39040/60032 (65%)]\tLoss: 0.456730\n",
      "Train Epoch: 1 [39680/60032 (66%)]\tLoss: 0.200555\n",
      "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.257252\n",
      "Train Epoch: 1 [40960/60032 (68%)]\tLoss: 0.197028\n",
      "Train Epoch: 1 [41600/60032 (69%)]\tLoss: 0.271620\n",
      "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.191695\n",
      "Train Epoch: 1 [42880/60032 (71%)]\tLoss: 0.119348\n",
      "Train Epoch: 1 [43520/60032 (72%)]\tLoss: 0.176628\n",
      "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.174886\n",
      "Train Epoch: 1 [44800/60032 (75%)]\tLoss: 0.192890\n",
      "Train Epoch: 1 [45440/60032 (76%)]\tLoss: 0.349346\n",
      "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.220804\n",
      "Train Epoch: 1 [46720/60032 (78%)]\tLoss: 0.191637\n",
      "Train Epoch: 1 [47360/60032 (79%)]\tLoss: 0.155322\n",
      "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.323142\n",
      "Train Epoch: 1 [48640/60032 (81%)]\tLoss: 0.245648\n",
      "Train Epoch: 1 [49280/60032 (82%)]\tLoss: 0.254449\n",
      "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.274805\n",
      "Train Epoch: 1 [50560/60032 (84%)]\tLoss: 0.266294\n",
      "Train Epoch: 1 [51200/60032 (85%)]\tLoss: 0.150608\n",
      "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.130444\n",
      "Train Epoch: 1 [52480/60032 (87%)]\tLoss: 0.273580\n",
      "Train Epoch: 1 [53120/60032 (88%)]\tLoss: 0.213447\n",
      "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.182463\n",
      "Train Epoch: 1 [54400/60032 (91%)]\tLoss: 0.141880\n",
      "Train Epoch: 1 [55040/60032 (92%)]\tLoss: 0.117726\n",
      "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.223215\n",
      "Train Epoch: 1 [56320/60032 (94%)]\tLoss: 0.214031\n",
      "Train Epoch: 1 [56960/60032 (95%)]\tLoss: 0.085399\n",
      "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.081299\n",
      "Train Epoch: 1 [58240/60032 (97%)]\tLoss: 0.120822\n",
      "Train Epoch: 1 [58880/60032 (98%)]\tLoss: 0.173020\n",
      "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.143058\n",
      "\n",
      "Test set: Average loss: 0.1575, Accuracy: 9512/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.102994\n",
      "Train Epoch: 2 [640/60032 (1%)]\tLoss: 0.245004\n",
      "Train Epoch: 2 [1280/60032 (2%)]\tLoss: 0.401740\n",
      "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.105846\n",
      "Train Epoch: 2 [2560/60032 (4%)]\tLoss: 0.348959\n",
      "Train Epoch: 2 [3200/60032 (5%)]\tLoss: 0.212345\n",
      "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.148415\n",
      "Train Epoch: 2 [4480/60032 (7%)]\tLoss: 0.192541\n",
      "Train Epoch: 2 [5120/60032 (9%)]\tLoss: 0.103121\n",
      "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.149521\n",
      "Train Epoch: 2 [6400/60032 (11%)]\tLoss: 0.147868\n",
      "Train Epoch: 2 [7040/60032 (12%)]\tLoss: 0.060578\n",
      "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.108171\n",
      "Train Epoch: 2 [8320/60032 (14%)]\tLoss: 0.151199\n",
      "Train Epoch: 2 [8960/60032 (15%)]\tLoss: 0.152722\n",
      "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.110857\n",
      "Train Epoch: 2 [10240/60032 (17%)]\tLoss: 0.187026\n",
      "Train Epoch: 2 [10880/60032 (18%)]\tLoss: 0.138701\n",
      "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.118648\n",
      "Train Epoch: 2 [12160/60032 (20%)]\tLoss: 0.220495\n",
      "Train Epoch: 2 [12800/60032 (21%)]\tLoss: 0.131019\n",
      "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.062667\n",
      "Train Epoch: 2 [14080/60032 (23%)]\tLoss: 0.124929\n",
      "Train Epoch: 2 [14720/60032 (25%)]\tLoss: 0.163047\n",
      "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.088611\n",
      "Train Epoch: 2 [16000/60032 (27%)]\tLoss: 0.149550\n",
      "Train Epoch: 2 [16640/60032 (28%)]\tLoss: 0.045510\n",
      "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.157012\n",
      "Train Epoch: 2 [17920/60032 (30%)]\tLoss: 0.133271\n",
      "Train Epoch: 2 [18560/60032 (31%)]\tLoss: 0.098171\n",
      "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.161198\n",
      "Train Epoch: 2 [19840/60032 (33%)]\tLoss: 0.053992\n",
      "Train Epoch: 2 [20480/60032 (34%)]\tLoss: 0.210320\n",
      "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.157591\n",
      "Train Epoch: 2 [21760/60032 (36%)]\tLoss: 0.115217\n",
      "Train Epoch: 2 [22400/60032 (37%)]\tLoss: 0.144262\n",
      "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.229963\n",
      "Train Epoch: 2 [23680/60032 (39%)]\tLoss: 0.074508\n",
      "Train Epoch: 2 [24320/60032 (41%)]\tLoss: 0.181387\n",
      "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.197294\n",
      "Train Epoch: 2 [25600/60032 (43%)]\tLoss: 0.068023\n",
      "Train Epoch: 2 [26240/60032 (44%)]\tLoss: 0.065397\n",
      "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.207241\n",
      "Train Epoch: 2 [27520/60032 (46%)]\tLoss: 0.115105\n",
      "Train Epoch: 2 [28160/60032 (47%)]\tLoss: 0.154207\n",
      "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.080152\n",
      "Train Epoch: 2 [29440/60032 (49%)]\tLoss: 0.125808\n",
      "Train Epoch: 2 [30080/60032 (50%)]\tLoss: 0.038396\n",
      "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.063565\n",
      "Train Epoch: 2 [31360/60032 (52%)]\tLoss: 0.074993\n",
      "Train Epoch: 2 [32000/60032 (53%)]\tLoss: 0.056027\n",
      "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.158901\n",
      "Train Epoch: 2 [33280/60032 (55%)]\tLoss: 0.162900\n",
      "Train Epoch: 2 [33920/60032 (57%)]\tLoss: 0.110448\n",
      "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.155816\n",
      "Train Epoch: 2 [35200/60032 (59%)]\tLoss: 0.074048\n",
      "Train Epoch: 2 [35840/60032 (60%)]\tLoss: 0.130446\n",
      "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.073850\n",
      "Train Epoch: 2 [37120/60032 (62%)]\tLoss: 0.092732\n",
      "Train Epoch: 2 [37760/60032 (63%)]\tLoss: 0.090462\n",
      "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.162218\n",
      "Train Epoch: 2 [39040/60032 (65%)]\tLoss: 0.128293\n",
      "Train Epoch: 2 [39680/60032 (66%)]\tLoss: 0.048594\n",
      "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.073595\n",
      "Train Epoch: 2 [40960/60032 (68%)]\tLoss: 0.114883\n",
      "Train Epoch: 2 [41600/60032 (69%)]\tLoss: 0.123153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.152885\n",
      "Train Epoch: 2 [42880/60032 (71%)]\tLoss: 0.137461\n",
      "Train Epoch: 2 [43520/60032 (72%)]\tLoss: 0.106532\n",
      "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.047505\n",
      "Train Epoch: 2 [44800/60032 (75%)]\tLoss: 0.101376\n",
      "Train Epoch: 2 [45440/60032 (76%)]\tLoss: 0.116271\n",
      "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.086508\n",
      "Train Epoch: 2 [46720/60032 (78%)]\tLoss: 0.072095\n",
      "Train Epoch: 2 [47360/60032 (79%)]\tLoss: 0.197535\n",
      "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.101396\n",
      "Train Epoch: 2 [48640/60032 (81%)]\tLoss: 0.082499\n",
      "Train Epoch: 2 [49280/60032 (82%)]\tLoss: 0.095054\n",
      "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.154378\n",
      "Train Epoch: 2 [50560/60032 (84%)]\tLoss: 0.105888\n",
      "Train Epoch: 2 [51200/60032 (85%)]\tLoss: 0.062209\n",
      "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.032265\n",
      "Train Epoch: 2 [52480/60032 (87%)]\tLoss: 0.169479\n",
      "Train Epoch: 2 [53120/60032 (88%)]\tLoss: 0.070053\n",
      "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.073180\n",
      "Train Epoch: 2 [54400/60032 (91%)]\tLoss: 0.049992\n",
      "Train Epoch: 2 [55040/60032 (92%)]\tLoss: 0.096885\n",
      "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.113541\n",
      "Train Epoch: 2 [56320/60032 (94%)]\tLoss: 0.091590\n",
      "Train Epoch: 2 [56960/60032 (95%)]\tLoss: 0.041783\n",
      "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.112854\n",
      "Train Epoch: 2 [58240/60032 (97%)]\tLoss: 0.084174\n",
      "Train Epoch: 2 [58880/60032 (98%)]\tLoss: 0.062957\n",
      "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.069326\n",
      "\n",
      "Test set: Average loss: 0.0901, Accuracy: 9734/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.081208\n",
      "Train Epoch: 3 [640/60032 (1%)]\tLoss: 0.115924\n",
      "Train Epoch: 3 [1280/60032 (2%)]\tLoss: 0.148420\n",
      "Train Epoch: 3 [1920/60032 (3%)]\tLoss: 0.079442\n",
      "Train Epoch: 3 [2560/60032 (4%)]\tLoss: 0.140582\n",
      "Train Epoch: 3 [3200/60032 (5%)]\tLoss: 0.089728\n",
      "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.184616\n",
      "Train Epoch: 3 [4480/60032 (7%)]\tLoss: 0.287411\n",
      "Train Epoch: 3 [5120/60032 (9%)]\tLoss: 0.263959\n",
      "Train Epoch: 3 [5760/60032 (10%)]\tLoss: 0.072485\n",
      "Train Epoch: 3 [6400/60032 (11%)]\tLoss: 0.130167\n",
      "Train Epoch: 3 [7040/60032 (12%)]\tLoss: 0.095709\n",
      "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.078213\n",
      "Train Epoch: 3 [8320/60032 (14%)]\tLoss: 0.040042\n",
      "Train Epoch: 3 [8960/60032 (15%)]\tLoss: 0.056185\n",
      "Train Epoch: 3 [9600/60032 (16%)]\tLoss: 0.204852\n",
      "Train Epoch: 3 [10240/60032 (17%)]\tLoss: 0.119105\n",
      "Train Epoch: 3 [10880/60032 (18%)]\tLoss: 0.132449\n",
      "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.247379\n",
      "Train Epoch: 3 [12160/60032 (20%)]\tLoss: 0.165727\n",
      "Train Epoch: 3 [12800/60032 (21%)]\tLoss: 0.030451\n",
      "Train Epoch: 3 [13440/60032 (22%)]\tLoss: 0.120331\n",
      "Train Epoch: 3 [14080/60032 (23%)]\tLoss: 0.089486\n",
      "Train Epoch: 3 [14720/60032 (25%)]\tLoss: 0.173065\n",
      "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.177648\n",
      "Train Epoch: 3 [16000/60032 (27%)]\tLoss: 0.156670\n",
      "Train Epoch: 3 [16640/60032 (28%)]\tLoss: 0.067103\n",
      "Train Epoch: 3 [17280/60032 (29%)]\tLoss: 0.151486\n",
      "Train Epoch: 3 [17920/60032 (30%)]\tLoss: 0.076685\n",
      "Train Epoch: 3 [18560/60032 (31%)]\tLoss: 0.016661\n",
      "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.028794\n",
      "Train Epoch: 3 [19840/60032 (33%)]\tLoss: 0.042866\n",
      "Train Epoch: 3 [20480/60032 (34%)]\tLoss: 0.029320\n",
      "Train Epoch: 3 [21120/60032 (35%)]\tLoss: 0.046746\n",
      "Train Epoch: 3 [21760/60032 (36%)]\tLoss: 0.121007\n",
      "Train Epoch: 3 [22400/60032 (37%)]\tLoss: 0.148295\n",
      "Train Epoch: 3 [23040/60032 (38%)]\tLoss: 0.055497\n",
      "Train Epoch: 3 [23680/60032 (39%)]\tLoss: 0.111281\n",
      "Train Epoch: 3 [24320/60032 (41%)]\tLoss: 0.055015\n",
      "Train Epoch: 3 [24960/60032 (42%)]\tLoss: 0.034852\n",
      "Train Epoch: 3 [25600/60032 (43%)]\tLoss: 0.204706\n",
      "Train Epoch: 3 [26240/60032 (44%)]\tLoss: 0.036365\n",
      "Train Epoch: 3 [26880/60032 (45%)]\tLoss: 0.290225\n",
      "Train Epoch: 3 [27520/60032 (46%)]\tLoss: 0.094747\n",
      "Train Epoch: 3 [28160/60032 (47%)]\tLoss: 0.089714\n",
      "Train Epoch: 3 [28800/60032 (48%)]\tLoss: 0.054614\n",
      "Train Epoch: 3 [29440/60032 (49%)]\tLoss: 0.157562\n",
      "Train Epoch: 3 [30080/60032 (50%)]\tLoss: 0.095994\n",
      "Train Epoch: 3 [30720/60032 (51%)]\tLoss: 0.063921\n",
      "Train Epoch: 3 [31360/60032 (52%)]\tLoss: 0.020022\n",
      "Train Epoch: 3 [32000/60032 (53%)]\tLoss: 0.041769\n",
      "Train Epoch: 3 [32640/60032 (54%)]\tLoss: 0.025000\n",
      "Train Epoch: 3 [33280/60032 (55%)]\tLoss: 0.051060\n",
      "Train Epoch: 3 [33920/60032 (57%)]\tLoss: 0.058672\n",
      "Train Epoch: 3 [34560/60032 (58%)]\tLoss: 0.070693\n",
      "Train Epoch: 3 [35200/60032 (59%)]\tLoss: 0.097234\n",
      "Train Epoch: 3 [35840/60032 (60%)]\tLoss: 0.165378\n",
      "Train Epoch: 3 [36480/60032 (61%)]\tLoss: 0.038818\n",
      "Train Epoch: 3 [37120/60032 (62%)]\tLoss: 0.143172\n",
      "Train Epoch: 3 [37760/60032 (63%)]\tLoss: 0.028916\n",
      "Train Epoch: 3 [38400/60032 (64%)]\tLoss: 0.033422\n",
      "Train Epoch: 3 [39040/60032 (65%)]\tLoss: 0.071607\n",
      "Train Epoch: 3 [39680/60032 (66%)]\tLoss: 0.019210\n",
      "Train Epoch: 3 [40320/60032 (67%)]\tLoss: 0.081574\n",
      "Train Epoch: 3 [40960/60032 (68%)]\tLoss: 0.018301\n",
      "Train Epoch: 3 [41600/60032 (69%)]\tLoss: 0.116731\n",
      "Train Epoch: 3 [42240/60032 (70%)]\tLoss: 0.168322\n",
      "Train Epoch: 3 [42880/60032 (71%)]\tLoss: 0.057834\n",
      "Train Epoch: 3 [43520/60032 (72%)]\tLoss: 0.052199\n",
      "Train Epoch: 3 [44160/60032 (74%)]\tLoss: 0.054627\n",
      "Train Epoch: 3 [44800/60032 (75%)]\tLoss: 0.026238\n",
      "Train Epoch: 3 [45440/60032 (76%)]\tLoss: 0.080355\n",
      "Train Epoch: 3 [46080/60032 (77%)]\tLoss: 0.073762\n",
      "Train Epoch: 3 [46720/60032 (78%)]\tLoss: 0.068746\n",
      "Train Epoch: 3 [47360/60032 (79%)]\tLoss: 0.116713\n",
      "Train Epoch: 3 [48000/60032 (80%)]\tLoss: 0.024666\n",
      "Train Epoch: 3 [48640/60032 (81%)]\tLoss: 0.186665\n",
      "Train Epoch: 3 [49280/60032 (82%)]\tLoss: 0.249587\n",
      "Train Epoch: 3 [49920/60032 (83%)]\tLoss: 0.098781\n",
      "Train Epoch: 3 [50560/60032 (84%)]\tLoss: 0.078239\n",
      "Train Epoch: 3 [51200/60032 (85%)]\tLoss: 0.146152\n",
      "Train Epoch: 3 [51840/60032 (86%)]\tLoss: 0.026800\n",
      "Train Epoch: 3 [52480/60032 (87%)]\tLoss: 0.112752\n",
      "Train Epoch: 3 [53120/60032 (88%)]\tLoss: 0.048937\n",
      "Train Epoch: 3 [53760/60032 (90%)]\tLoss: 0.055561\n",
      "Train Epoch: 3 [54400/60032 (91%)]\tLoss: 0.078696\n",
      "Train Epoch: 3 [55040/60032 (92%)]\tLoss: 0.049383\n",
      "Train Epoch: 3 [55680/60032 (93%)]\tLoss: 0.067876\n",
      "Train Epoch: 3 [56320/60032 (94%)]\tLoss: 0.019292\n",
      "Train Epoch: 3 [56960/60032 (95%)]\tLoss: 0.077383\n",
      "Train Epoch: 3 [57600/60032 (96%)]\tLoss: 0.056899\n",
      "Train Epoch: 3 [58240/60032 (97%)]\tLoss: 0.054853\n",
      "Train Epoch: 3 [58880/60032 (98%)]\tLoss: 0.017102\n",
      "Train Epoch: 3 [59520/60032 (99%)]\tLoss: 0.465166\n",
      "\n",
      "Test set: Average loss: 0.0740, Accuracy: 9758/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.147105\n",
      "Train Epoch: 4 [640/60032 (1%)]\tLoss: 0.142316\n",
      "Train Epoch: 4 [1280/60032 (2%)]\tLoss: 0.027474\n",
      "Train Epoch: 4 [1920/60032 (3%)]\tLoss: 0.065712\n",
      "Train Epoch: 4 [2560/60032 (4%)]\tLoss: 0.088945\n",
      "Train Epoch: 4 [3200/60032 (5%)]\tLoss: 0.098032\n",
      "Train Epoch: 4 [3840/60032 (6%)]\tLoss: 0.046091\n",
      "Train Epoch: 4 [4480/60032 (7%)]\tLoss: 0.089763\n",
      "Train Epoch: 4 [5120/60032 (9%)]\tLoss: 0.102571\n",
      "Train Epoch: 4 [5760/60032 (10%)]\tLoss: 0.102554\n",
      "Train Epoch: 4 [6400/60032 (11%)]\tLoss: 0.018206\n",
      "Train Epoch: 4 [7040/60032 (12%)]\tLoss: 0.076626\n",
      "Train Epoch: 4 [7680/60032 (13%)]\tLoss: 0.038290\n",
      "Train Epoch: 4 [8320/60032 (14%)]\tLoss: 0.030198\n",
      "Train Epoch: 4 [8960/60032 (15%)]\tLoss: 0.027109\n",
      "Train Epoch: 4 [9600/60032 (16%)]\tLoss: 0.069391\n",
      "Train Epoch: 4 [10240/60032 (17%)]\tLoss: 0.031733\n",
      "Train Epoch: 4 [10880/60032 (18%)]\tLoss: 0.078867\n",
      "Train Epoch: 4 [11520/60032 (19%)]\tLoss: 0.117539\n",
      "Train Epoch: 4 [12160/60032 (20%)]\tLoss: 0.108065\n",
      "Train Epoch: 4 [12800/60032 (21%)]\tLoss: 0.034403\n",
      "Train Epoch: 4 [13440/60032 (22%)]\tLoss: 0.105836\n",
      "Train Epoch: 4 [14080/60032 (23%)]\tLoss: 0.227551\n",
      "Train Epoch: 4 [14720/60032 (25%)]\tLoss: 0.015715\n",
      "Train Epoch: 4 [15360/60032 (26%)]\tLoss: 0.046209\n",
      "Train Epoch: 4 [16000/60032 (27%)]\tLoss: 0.064584\n",
      "Train Epoch: 4 [16640/60032 (28%)]\tLoss: 0.144772\n",
      "Train Epoch: 4 [17280/60032 (29%)]\tLoss: 0.047516\n",
      "Train Epoch: 4 [17920/60032 (30%)]\tLoss: 0.038795\n",
      "Train Epoch: 4 [18560/60032 (31%)]\tLoss: 0.045443\n",
      "Train Epoch: 4 [19200/60032 (32%)]\tLoss: 0.073231\n",
      "Train Epoch: 4 [19840/60032 (33%)]\tLoss: 0.041228\n",
      "Train Epoch: 4 [20480/60032 (34%)]\tLoss: 0.035195\n",
      "Train Epoch: 4 [21120/60032 (35%)]\tLoss: 0.084483\n",
      "Train Epoch: 4 [21760/60032 (36%)]\tLoss: 0.027675\n",
      "Train Epoch: 4 [22400/60032 (37%)]\tLoss: 0.062416\n",
      "Train Epoch: 4 [23040/60032 (38%)]\tLoss: 0.025041\n",
      "Train Epoch: 4 [23680/60032 (39%)]\tLoss: 0.112445\n",
      "Train Epoch: 4 [24320/60032 (41%)]\tLoss: 0.088168\n",
      "Train Epoch: 4 [24960/60032 (42%)]\tLoss: 0.143474\n",
      "Train Epoch: 4 [25600/60032 (43%)]\tLoss: 0.099177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [26240/60032 (44%)]\tLoss: 0.160822\n",
      "Train Epoch: 4 [26880/60032 (45%)]\tLoss: 0.176536\n",
      "Train Epoch: 4 [27520/60032 (46%)]\tLoss: 0.027268\n",
      "Train Epoch: 4 [28160/60032 (47%)]\tLoss: 0.062978\n",
      "Train Epoch: 4 [28800/60032 (48%)]\tLoss: 0.095246\n",
      "Train Epoch: 4 [29440/60032 (49%)]\tLoss: 0.151630\n",
      "Train Epoch: 4 [30080/60032 (50%)]\tLoss: 0.024575\n",
      "Train Epoch: 4 [30720/60032 (51%)]\tLoss: 0.018906\n",
      "Train Epoch: 4 [31360/60032 (52%)]\tLoss: 0.145415\n",
      "Train Epoch: 4 [32000/60032 (53%)]\tLoss: 0.021711\n",
      "Train Epoch: 4 [32640/60032 (54%)]\tLoss: 0.149366\n",
      "Train Epoch: 4 [33280/60032 (55%)]\tLoss: 0.057330\n",
      "Train Epoch: 4 [33920/60032 (57%)]\tLoss: 0.087206\n",
      "Train Epoch: 4 [34560/60032 (58%)]\tLoss: 0.030220\n",
      "Train Epoch: 4 [35200/60032 (59%)]\tLoss: 0.064036\n",
      "Train Epoch: 4 [35840/60032 (60%)]\tLoss: 0.098348\n",
      "Train Epoch: 4 [36480/60032 (61%)]\tLoss: 0.009968\n",
      "Train Epoch: 4 [37120/60032 (62%)]\tLoss: 0.057219\n",
      "Train Epoch: 4 [37760/60032 (63%)]\tLoss: 0.080713\n",
      "Train Epoch: 4 [38400/60032 (64%)]\tLoss: 0.044555\n",
      "Train Epoch: 4 [39040/60032 (65%)]\tLoss: 0.024697\n",
      "Train Epoch: 4 [39680/60032 (66%)]\tLoss: 0.090785\n",
      "Train Epoch: 4 [40320/60032 (67%)]\tLoss: 0.050026\n",
      "Train Epoch: 4 [40960/60032 (68%)]\tLoss: 0.012560\n",
      "Train Epoch: 4 [41600/60032 (69%)]\tLoss: 0.131726\n",
      "Train Epoch: 4 [42240/60032 (70%)]\tLoss: 0.138280\n",
      "Train Epoch: 4 [42880/60032 (71%)]\tLoss: 0.032445\n",
      "Train Epoch: 4 [43520/60032 (72%)]\tLoss: 0.026770\n",
      "Train Epoch: 4 [44160/60032 (74%)]\tLoss: 0.058425\n",
      "Train Epoch: 4 [44800/60032 (75%)]\tLoss: 0.059700\n",
      "Train Epoch: 4 [45440/60032 (76%)]\tLoss: 0.076902\n",
      "Train Epoch: 4 [46080/60032 (77%)]\tLoss: 0.020861\n",
      "Train Epoch: 4 [46720/60032 (78%)]\tLoss: 0.044198\n",
      "Train Epoch: 4 [47360/60032 (79%)]\tLoss: 0.068906\n",
      "Train Epoch: 4 [48000/60032 (80%)]\tLoss: 0.040123\n",
      "Train Epoch: 4 [48640/60032 (81%)]\tLoss: 0.026213\n",
      "Train Epoch: 4 [49280/60032 (82%)]\tLoss: 0.129168\n",
      "Train Epoch: 4 [49920/60032 (83%)]\tLoss: 0.167540\n",
      "Train Epoch: 4 [50560/60032 (84%)]\tLoss: 0.023438\n",
      "Train Epoch: 4 [51200/60032 (85%)]\tLoss: 0.089004\n",
      "Train Epoch: 4 [51840/60032 (86%)]\tLoss: 0.067411\n",
      "Train Epoch: 4 [52480/60032 (87%)]\tLoss: 0.016197\n",
      "Train Epoch: 4 [53120/60032 (88%)]\tLoss: 0.075432\n",
      "Train Epoch: 4 [53760/60032 (90%)]\tLoss: 0.064485\n",
      "Train Epoch: 4 [54400/60032 (91%)]\tLoss: 0.152462\n",
      "Train Epoch: 4 [55040/60032 (92%)]\tLoss: 0.083092\n",
      "Train Epoch: 4 [55680/60032 (93%)]\tLoss: 0.073988\n",
      "Train Epoch: 4 [56320/60032 (94%)]\tLoss: 0.047540\n",
      "Train Epoch: 4 [56960/60032 (95%)]\tLoss: 0.055323\n",
      "Train Epoch: 4 [57600/60032 (96%)]\tLoss: 0.061741\n",
      "Train Epoch: 4 [58240/60032 (97%)]\tLoss: 0.024572\n",
      "Train Epoch: 4 [58880/60032 (98%)]\tLoss: 0.055546\n",
      "Train Epoch: 4 [59520/60032 (99%)]\tLoss: 0.017440\n",
      "\n",
      "Test set: Average loss: 0.0549, Accuracy: 9812/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.082141\n",
      "Train Epoch: 5 [640/60032 (1%)]\tLoss: 0.196319\n",
      "Train Epoch: 5 [1280/60032 (2%)]\tLoss: 0.028409\n",
      "Train Epoch: 5 [1920/60032 (3%)]\tLoss: 0.039028\n",
      "Train Epoch: 5 [2560/60032 (4%)]\tLoss: 0.027335\n",
      "Train Epoch: 5 [3200/60032 (5%)]\tLoss: 0.013848\n",
      "Train Epoch: 5 [3840/60032 (6%)]\tLoss: 0.028862\n",
      "Train Epoch: 5 [4480/60032 (7%)]\tLoss: 0.150802\n",
      "Train Epoch: 5 [5120/60032 (9%)]\tLoss: 0.051180\n",
      "Train Epoch: 5 [5760/60032 (10%)]\tLoss: 0.035448\n",
      "Train Epoch: 5 [6400/60032 (11%)]\tLoss: 0.110504\n",
      "Train Epoch: 5 [7040/60032 (12%)]\tLoss: 0.086249\n",
      "Train Epoch: 5 [7680/60032 (13%)]\tLoss: 0.064599\n",
      "Train Epoch: 5 [8320/60032 (14%)]\tLoss: 0.068405\n",
      "Train Epoch: 5 [8960/60032 (15%)]\tLoss: 0.154179\n",
      "Train Epoch: 5 [9600/60032 (16%)]\tLoss: 0.021344\n",
      "Train Epoch: 5 [10240/60032 (17%)]\tLoss: 0.021116\n",
      "Train Epoch: 5 [10880/60032 (18%)]\tLoss: 0.018254\n",
      "Train Epoch: 5 [11520/60032 (19%)]\tLoss: 0.165273\n",
      "Train Epoch: 5 [12160/60032 (20%)]\tLoss: 0.160734\n",
      "Train Epoch: 5 [12800/60032 (21%)]\tLoss: 0.128963\n",
      "Train Epoch: 5 [13440/60032 (22%)]\tLoss: 0.046098\n",
      "Train Epoch: 5 [14080/60032 (23%)]\tLoss: 0.026318\n",
      "Train Epoch: 5 [14720/60032 (25%)]\tLoss: 0.065406\n",
      "Train Epoch: 5 [15360/60032 (26%)]\tLoss: 0.101752\n",
      "Train Epoch: 5 [16000/60032 (27%)]\tLoss: 0.027732\n",
      "Train Epoch: 5 [16640/60032 (28%)]\tLoss: 0.018928\n",
      "Train Epoch: 5 [17280/60032 (29%)]\tLoss: 0.054622\n",
      "Train Epoch: 5 [17920/60032 (30%)]\tLoss: 0.041337\n",
      "Train Epoch: 5 [18560/60032 (31%)]\tLoss: 0.056544\n",
      "Train Epoch: 5 [19200/60032 (32%)]\tLoss: 0.034500\n",
      "Train Epoch: 5 [19840/60032 (33%)]\tLoss: 0.036242\n",
      "Train Epoch: 5 [20480/60032 (34%)]\tLoss: 0.032727\n",
      "Train Epoch: 5 [21120/60032 (35%)]\tLoss: 0.100400\n",
      "Train Epoch: 5 [21760/60032 (36%)]\tLoss: 0.080653\n",
      "Train Epoch: 5 [22400/60032 (37%)]\tLoss: 0.041208\n",
      "Train Epoch: 5 [23040/60032 (38%)]\tLoss: 0.031325\n",
      "Train Epoch: 5 [23680/60032 (39%)]\tLoss: 0.022598\n",
      "Train Epoch: 5 [24320/60032 (41%)]\tLoss: 0.067309\n",
      "Train Epoch: 5 [24960/60032 (42%)]\tLoss: 0.026463\n",
      "Train Epoch: 5 [25600/60032 (43%)]\tLoss: 0.082877\n",
      "Train Epoch: 5 [26240/60032 (44%)]\tLoss: 0.149140\n",
      "Train Epoch: 5 [26880/60032 (45%)]\tLoss: 0.021702\n",
      "Train Epoch: 5 [27520/60032 (46%)]\tLoss: 0.101003\n",
      "Train Epoch: 5 [28160/60032 (47%)]\tLoss: 0.024156\n",
      "Train Epoch: 5 [28800/60032 (48%)]\tLoss: 0.017915\n",
      "Train Epoch: 5 [29440/60032 (49%)]\tLoss: 0.104959\n",
      "Train Epoch: 5 [30080/60032 (50%)]\tLoss: 0.047891\n",
      "Train Epoch: 5 [30720/60032 (51%)]\tLoss: 0.037665\n",
      "Train Epoch: 5 [31360/60032 (52%)]\tLoss: 0.054179\n",
      "Train Epoch: 5 [32000/60032 (53%)]\tLoss: 0.094909\n",
      "Train Epoch: 5 [32640/60032 (54%)]\tLoss: 0.070441\n",
      "Train Epoch: 5 [33280/60032 (55%)]\tLoss: 0.054799\n",
      "Train Epoch: 5 [33920/60032 (57%)]\tLoss: 0.051914\n",
      "Train Epoch: 5 [34560/60032 (58%)]\tLoss: 0.112149\n",
      "Train Epoch: 5 [35200/60032 (59%)]\tLoss: 0.130963\n",
      "Train Epoch: 5 [35840/60032 (60%)]\tLoss: 0.078489\n",
      "Train Epoch: 5 [36480/60032 (61%)]\tLoss: 0.037577\n",
      "Train Epoch: 5 [37120/60032 (62%)]\tLoss: 0.045600\n",
      "Train Epoch: 5 [37760/60032 (63%)]\tLoss: 0.020385\n",
      "Train Epoch: 5 [38400/60032 (64%)]\tLoss: 0.028798\n",
      "Train Epoch: 5 [39040/60032 (65%)]\tLoss: 0.139620\n",
      "Train Epoch: 5 [39680/60032 (66%)]\tLoss: 0.071690\n",
      "Train Epoch: 5 [40320/60032 (67%)]\tLoss: 0.011698\n",
      "Train Epoch: 5 [40960/60032 (68%)]\tLoss: 0.031692\n",
      "Train Epoch: 5 [41600/60032 (69%)]\tLoss: 0.356007\n",
      "Train Epoch: 5 [42240/60032 (70%)]\tLoss: 0.025857\n",
      "Train Epoch: 5 [42880/60032 (71%)]\tLoss: 0.032671\n",
      "Train Epoch: 5 [43520/60032 (72%)]\tLoss: 0.022550\n",
      "Train Epoch: 5 [44160/60032 (74%)]\tLoss: 0.017317\n",
      "Train Epoch: 5 [44800/60032 (75%)]\tLoss: 0.042117\n",
      "Train Epoch: 5 [45440/60032 (76%)]\tLoss: 0.009701\n",
      "Train Epoch: 5 [46080/60032 (77%)]\tLoss: 0.022205\n",
      "Train Epoch: 5 [46720/60032 (78%)]\tLoss: 0.041021\n",
      "Train Epoch: 5 [47360/60032 (79%)]\tLoss: 0.039703\n",
      "Train Epoch: 5 [48000/60032 (80%)]\tLoss: 0.015700\n",
      "Train Epoch: 5 [48640/60032 (81%)]\tLoss: 0.009246\n",
      "Train Epoch: 5 [49280/60032 (82%)]\tLoss: 0.040353\n",
      "Train Epoch: 5 [49920/60032 (83%)]\tLoss: 0.064918\n",
      "Train Epoch: 5 [50560/60032 (84%)]\tLoss: 0.019972\n",
      "Train Epoch: 5 [51200/60032 (85%)]\tLoss: 0.049320\n",
      "Train Epoch: 5 [51840/60032 (86%)]\tLoss: 0.039641\n",
      "Train Epoch: 5 [52480/60032 (87%)]\tLoss: 0.020852\n",
      "Train Epoch: 5 [53120/60032 (88%)]\tLoss: 0.050025\n",
      "Train Epoch: 5 [53760/60032 (90%)]\tLoss: 0.016785\n",
      "Train Epoch: 5 [54400/60032 (91%)]\tLoss: 0.031622\n",
      "Train Epoch: 5 [55040/60032 (92%)]\tLoss: 0.063702\n",
      "Train Epoch: 5 [55680/60032 (93%)]\tLoss: 0.098527\n",
      "Train Epoch: 5 [56320/60032 (94%)]\tLoss: 0.012455\n",
      "Train Epoch: 5 [56960/60032 (95%)]\tLoss: 0.016397\n",
      "Train Epoch: 5 [57600/60032 (96%)]\tLoss: 0.026493\n",
      "Train Epoch: 5 [58240/60032 (97%)]\tLoss: 0.046211\n",
      "Train Epoch: 5 [58880/60032 (98%)]\tLoss: 0.015166\n",
      "Train Epoch: 5 [59520/60032 (99%)]\tLoss: 0.062346\n",
      "\n",
      "Test set: Average loss: 0.0461, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60032 (0%)]\tLoss: 0.051576\n",
      "Train Epoch: 6 [640/60032 (1%)]\tLoss: 0.040656\n",
      "Train Epoch: 6 [1280/60032 (2%)]\tLoss: 0.101489\n",
      "Train Epoch: 6 [1920/60032 (3%)]\tLoss: 0.100939\n",
      "Train Epoch: 6 [2560/60032 (4%)]\tLoss: 0.060813\n",
      "Train Epoch: 6 [3200/60032 (5%)]\tLoss: 0.025440\n",
      "Train Epoch: 6 [3840/60032 (6%)]\tLoss: 0.011995\n",
      "Train Epoch: 6 [4480/60032 (7%)]\tLoss: 0.033485\n",
      "Train Epoch: 6 [5120/60032 (9%)]\tLoss: 0.063169\n",
      "Train Epoch: 6 [5760/60032 (10%)]\tLoss: 0.091021\n",
      "Train Epoch: 6 [6400/60032 (11%)]\tLoss: 0.012059\n",
      "Train Epoch: 6 [7040/60032 (12%)]\tLoss: 0.048163\n",
      "Train Epoch: 6 [7680/60032 (13%)]\tLoss: 0.111872\n",
      "Train Epoch: 6 [8320/60032 (14%)]\tLoss: 0.048600\n",
      "Train Epoch: 6 [8960/60032 (15%)]\tLoss: 0.026255\n",
      "Train Epoch: 6 [9600/60032 (16%)]\tLoss: 0.014436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [10240/60032 (17%)]\tLoss: 0.084168\n",
      "Train Epoch: 6 [10880/60032 (18%)]\tLoss: 0.014655\n",
      "Train Epoch: 6 [11520/60032 (19%)]\tLoss: 0.086800\n",
      "Train Epoch: 6 [12160/60032 (20%)]\tLoss: 0.038284\n",
      "Train Epoch: 6 [12800/60032 (21%)]\tLoss: 0.039181\n",
      "Train Epoch: 6 [13440/60032 (22%)]\tLoss: 0.037182\n",
      "Train Epoch: 6 [14080/60032 (23%)]\tLoss: 0.032302\n",
      "Train Epoch: 6 [14720/60032 (25%)]\tLoss: 0.034672\n",
      "Train Epoch: 6 [15360/60032 (26%)]\tLoss: 0.097992\n",
      "Train Epoch: 6 [16000/60032 (27%)]\tLoss: 0.064300\n",
      "Train Epoch: 6 [16640/60032 (28%)]\tLoss: 0.074520\n",
      "Train Epoch: 6 [17280/60032 (29%)]\tLoss: 0.052494\n",
      "Train Epoch: 6 [17920/60032 (30%)]\tLoss: 0.006776\n",
      "Train Epoch: 6 [18560/60032 (31%)]\tLoss: 0.073455\n",
      "Train Epoch: 6 [19200/60032 (32%)]\tLoss: 0.043032\n",
      "Train Epoch: 6 [19840/60032 (33%)]\tLoss: 0.036362\n",
      "Train Epoch: 6 [20480/60032 (34%)]\tLoss: 0.048331\n",
      "Train Epoch: 6 [21120/60032 (35%)]\tLoss: 0.073197\n",
      "Train Epoch: 6 [21760/60032 (36%)]\tLoss: 0.084559\n",
      "Train Epoch: 6 [22400/60032 (37%)]\tLoss: 0.114878\n",
      "Train Epoch: 6 [23040/60032 (38%)]\tLoss: 0.047718\n",
      "Train Epoch: 6 [23680/60032 (39%)]\tLoss: 0.075408\n",
      "Train Epoch: 6 [24320/60032 (41%)]\tLoss: 0.002736\n",
      "Train Epoch: 6 [24960/60032 (42%)]\tLoss: 0.007875\n",
      "Train Epoch: 6 [25600/60032 (43%)]\tLoss: 0.015225\n",
      "Train Epoch: 6 [26240/60032 (44%)]\tLoss: 0.014215\n",
      "Train Epoch: 6 [26880/60032 (45%)]\tLoss: 0.019800\n",
      "Train Epoch: 6 [27520/60032 (46%)]\tLoss: 0.044371\n",
      "Train Epoch: 6 [28160/60032 (47%)]\tLoss: 0.052350\n",
      "Train Epoch: 6 [28800/60032 (48%)]\tLoss: 0.034923\n",
      "Train Epoch: 6 [29440/60032 (49%)]\tLoss: 0.036011\n",
      "Train Epoch: 6 [30080/60032 (50%)]\tLoss: 0.022868\n",
      "Train Epoch: 6 [30720/60032 (51%)]\tLoss: 0.084981\n",
      "Train Epoch: 6 [31360/60032 (52%)]\tLoss: 0.037785\n",
      "Train Epoch: 6 [32000/60032 (53%)]\tLoss: 0.061676\n",
      "Train Epoch: 6 [32640/60032 (54%)]\tLoss: 0.010651\n",
      "Train Epoch: 6 [33280/60032 (55%)]\tLoss: 0.037352\n",
      "Train Epoch: 6 [33920/60032 (57%)]\tLoss: 0.031676\n",
      "Train Epoch: 6 [34560/60032 (58%)]\tLoss: 0.026626\n",
      "Train Epoch: 6 [35200/60032 (59%)]\tLoss: 0.053113\n",
      "Train Epoch: 6 [35840/60032 (60%)]\tLoss: 0.034062\n",
      "Train Epoch: 6 [36480/60032 (61%)]\tLoss: 0.048206\n",
      "Train Epoch: 6 [37120/60032 (62%)]\tLoss: 0.084176\n",
      "Train Epoch: 6 [37760/60032 (63%)]\tLoss: 0.026420\n",
      "Train Epoch: 6 [38400/60032 (64%)]\tLoss: 0.006613\n",
      "Train Epoch: 6 [39040/60032 (65%)]\tLoss: 0.045439\n",
      "Train Epoch: 6 [39680/60032 (66%)]\tLoss: 0.024540\n",
      "Train Epoch: 6 [40320/60032 (67%)]\tLoss: 0.076258\n",
      "Train Epoch: 6 [40960/60032 (68%)]\tLoss: 0.018986\n",
      "Train Epoch: 6 [41600/60032 (69%)]\tLoss: 0.021920\n",
      "Train Epoch: 6 [42240/60032 (70%)]\tLoss: 0.041071\n",
      "Train Epoch: 6 [42880/60032 (71%)]\tLoss: 0.062564\n",
      "Train Epoch: 6 [43520/60032 (72%)]\tLoss: 0.080488\n",
      "Train Epoch: 6 [44160/60032 (74%)]\tLoss: 0.007714\n",
      "Train Epoch: 6 [44800/60032 (75%)]\tLoss: 0.121458\n",
      "Train Epoch: 6 [45440/60032 (76%)]\tLoss: 0.005627\n",
      "Train Epoch: 6 [46080/60032 (77%)]\tLoss: 0.065200\n",
      "Train Epoch: 6 [46720/60032 (78%)]\tLoss: 0.034408\n",
      "Train Epoch: 6 [47360/60032 (79%)]\tLoss: 0.224876\n",
      "Train Epoch: 6 [48000/60032 (80%)]\tLoss: 0.050883\n",
      "Train Epoch: 6 [48640/60032 (81%)]\tLoss: 0.130618\n",
      "Train Epoch: 6 [49280/60032 (82%)]\tLoss: 0.005293\n",
      "Train Epoch: 6 [49920/60032 (83%)]\tLoss: 0.025248\n",
      "Train Epoch: 6 [50560/60032 (84%)]\tLoss: 0.005851\n",
      "Train Epoch: 6 [51200/60032 (85%)]\tLoss: 0.019377\n",
      "Train Epoch: 6 [51840/60032 (86%)]\tLoss: 0.030883\n",
      "Train Epoch: 6 [52480/60032 (87%)]\tLoss: 0.161705\n",
      "Train Epoch: 6 [53120/60032 (88%)]\tLoss: 0.017231\n",
      "Train Epoch: 6 [53760/60032 (90%)]\tLoss: 0.053281\n",
      "Train Epoch: 6 [54400/60032 (91%)]\tLoss: 0.067027\n",
      "Train Epoch: 6 [55040/60032 (92%)]\tLoss: 0.015431\n",
      "Train Epoch: 6 [55680/60032 (93%)]\tLoss: 0.024945\n",
      "Train Epoch: 6 [56320/60032 (94%)]\tLoss: 0.021937\n",
      "Train Epoch: 6 [56960/60032 (95%)]\tLoss: 0.107892\n",
      "Train Epoch: 6 [57600/60032 (96%)]\tLoss: 0.101875\n",
      "Train Epoch: 6 [58240/60032 (97%)]\tLoss: 0.067987\n",
      "Train Epoch: 6 [58880/60032 (98%)]\tLoss: 0.095135\n",
      "Train Epoch: 6 [59520/60032 (99%)]\tLoss: 0.012131\n",
      "\n",
      "Test set: Average loss: 0.0441, Accuracy: 9863/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60032 (0%)]\tLoss: 0.047407\n",
      "Train Epoch: 7 [640/60032 (1%)]\tLoss: 0.033969\n",
      "Train Epoch: 7 [1280/60032 (2%)]\tLoss: 0.108221\n",
      "Train Epoch: 7 [1920/60032 (3%)]\tLoss: 0.021392\n",
      "Train Epoch: 7 [2560/60032 (4%)]\tLoss: 0.052484\n",
      "Train Epoch: 7 [3200/60032 (5%)]\tLoss: 0.014159\n",
      "Train Epoch: 7 [3840/60032 (6%)]\tLoss: 0.012760\n",
      "Train Epoch: 7 [4480/60032 (7%)]\tLoss: 0.007438\n",
      "Train Epoch: 7 [5120/60032 (9%)]\tLoss: 0.008384\n",
      "Train Epoch: 7 [5760/60032 (10%)]\tLoss: 0.040571\n",
      "Train Epoch: 7 [6400/60032 (11%)]\tLoss: 0.053273\n",
      "Train Epoch: 7 [7040/60032 (12%)]\tLoss: 0.045588\n",
      "Train Epoch: 7 [7680/60032 (13%)]\tLoss: 0.107955\n",
      "Train Epoch: 7 [8320/60032 (14%)]\tLoss: 0.032787\n",
      "Train Epoch: 7 [8960/60032 (15%)]\tLoss: 0.012100\n",
      "Train Epoch: 7 [9600/60032 (16%)]\tLoss: 0.026907\n",
      "Train Epoch: 7 [10240/60032 (17%)]\tLoss: 0.021096\n",
      "Train Epoch: 7 [10880/60032 (18%)]\tLoss: 0.054884\n",
      "Train Epoch: 7 [11520/60032 (19%)]\tLoss: 0.077063\n",
      "Train Epoch: 7 [12160/60032 (20%)]\tLoss: 0.029264\n",
      "Train Epoch: 7 [12800/60032 (21%)]\tLoss: 0.070149\n",
      "Train Epoch: 7 [13440/60032 (22%)]\tLoss: 0.019945\n",
      "Train Epoch: 7 [14080/60032 (23%)]\tLoss: 0.005087\n",
      "Train Epoch: 7 [14720/60032 (25%)]\tLoss: 0.029787\n",
      "Train Epoch: 7 [15360/60032 (26%)]\tLoss: 0.027481\n",
      "Train Epoch: 7 [16000/60032 (27%)]\tLoss: 0.103631\n",
      "Train Epoch: 7 [16640/60032 (28%)]\tLoss: 0.081116\n",
      "Train Epoch: 7 [17280/60032 (29%)]\tLoss: 0.163376\n",
      "Train Epoch: 7 [17920/60032 (30%)]\tLoss: 0.015871\n",
      "Train Epoch: 7 [18560/60032 (31%)]\tLoss: 0.032148\n",
      "Train Epoch: 7 [19200/60032 (32%)]\tLoss: 0.089444\n",
      "Train Epoch: 7 [19840/60032 (33%)]\tLoss: 0.040583\n",
      "Train Epoch: 7 [20480/60032 (34%)]\tLoss: 0.067486\n",
      "Train Epoch: 7 [21120/60032 (35%)]\tLoss: 0.061649\n",
      "Train Epoch: 7 [21760/60032 (36%)]\tLoss: 0.234147\n",
      "Train Epoch: 7 [22400/60032 (37%)]\tLoss: 0.012450\n",
      "Train Epoch: 7 [23040/60032 (38%)]\tLoss: 0.014439\n",
      "Train Epoch: 7 [23680/60032 (39%)]\tLoss: 0.022269\n",
      "Train Epoch: 7 [24320/60032 (41%)]\tLoss: 0.013562\n",
      "Train Epoch: 7 [24960/60032 (42%)]\tLoss: 0.084624\n",
      "Train Epoch: 7 [25600/60032 (43%)]\tLoss: 0.033826\n",
      "Train Epoch: 7 [26240/60032 (44%)]\tLoss: 0.199243\n",
      "Train Epoch: 7 [26880/60032 (45%)]\tLoss: 0.020833\n",
      "Train Epoch: 7 [27520/60032 (46%)]\tLoss: 0.040380\n",
      "Train Epoch: 7 [28160/60032 (47%)]\tLoss: 0.005292\n",
      "Train Epoch: 7 [28800/60032 (48%)]\tLoss: 0.013530\n",
      "Train Epoch: 7 [29440/60032 (49%)]\tLoss: 0.009738\n",
      "Train Epoch: 7 [30080/60032 (50%)]\tLoss: 0.064514\n",
      "Train Epoch: 7 [30720/60032 (51%)]\tLoss: 0.009569\n",
      "Train Epoch: 7 [31360/60032 (52%)]\tLoss: 0.011853\n",
      "Train Epoch: 7 [32000/60032 (53%)]\tLoss: 0.010524\n",
      "Train Epoch: 7 [32640/60032 (54%)]\tLoss: 0.058498\n",
      "Train Epoch: 7 [33280/60032 (55%)]\tLoss: 0.008434\n",
      "Train Epoch: 7 [33920/60032 (57%)]\tLoss: 0.016524\n",
      "Train Epoch: 7 [34560/60032 (58%)]\tLoss: 0.023722\n",
      "Train Epoch: 7 [35200/60032 (59%)]\tLoss: 0.035204\n",
      "Train Epoch: 7 [35840/60032 (60%)]\tLoss: 0.140961\n",
      "Train Epoch: 7 [36480/60032 (61%)]\tLoss: 0.029964\n",
      "Train Epoch: 7 [37120/60032 (62%)]\tLoss: 0.009282\n",
      "Train Epoch: 7 [37760/60032 (63%)]\tLoss: 0.031802\n",
      "Train Epoch: 7 [38400/60032 (64%)]\tLoss: 0.042292\n",
      "Train Epoch: 7 [39040/60032 (65%)]\tLoss: 0.037724\n",
      "Train Epoch: 7 [39680/60032 (66%)]\tLoss: 0.177031\n",
      "Train Epoch: 7 [40320/60032 (67%)]\tLoss: 0.036759\n",
      "Train Epoch: 7 [40960/60032 (68%)]\tLoss: 0.069258\n",
      "Train Epoch: 7 [41600/60032 (69%)]\tLoss: 0.015344\n",
      "Train Epoch: 7 [42240/60032 (70%)]\tLoss: 0.012583\n",
      "Train Epoch: 7 [42880/60032 (71%)]\tLoss: 0.005516\n",
      "Train Epoch: 7 [43520/60032 (72%)]\tLoss: 0.009450\n",
      "Train Epoch: 7 [44160/60032 (74%)]\tLoss: 0.008993\n",
      "Train Epoch: 7 [44800/60032 (75%)]\tLoss: 0.054976\n",
      "Train Epoch: 7 [45440/60032 (76%)]\tLoss: 0.002764\n",
      "Train Epoch: 7 [46080/60032 (77%)]\tLoss: 0.058512\n",
      "Train Epoch: 7 [46720/60032 (78%)]\tLoss: 0.023189\n",
      "Train Epoch: 7 [47360/60032 (79%)]\tLoss: 0.087720\n",
      "Train Epoch: 7 [48000/60032 (80%)]\tLoss: 0.044164\n",
      "Train Epoch: 7 [48640/60032 (81%)]\tLoss: 0.129658\n",
      "Train Epoch: 7 [49280/60032 (82%)]\tLoss: 0.030371\n",
      "Train Epoch: 7 [49920/60032 (83%)]\tLoss: 0.071142\n",
      "Train Epoch: 7 [50560/60032 (84%)]\tLoss: 0.040231\n",
      "Train Epoch: 7 [51200/60032 (85%)]\tLoss: 0.249400\n",
      "Train Epoch: 7 [51840/60032 (86%)]\tLoss: 0.038591\n",
      "Train Epoch: 7 [52480/60032 (87%)]\tLoss: 0.029897\n",
      "Train Epoch: 7 [53120/60032 (88%)]\tLoss: 0.114893\n",
      "Train Epoch: 7 [53760/60032 (90%)]\tLoss: 0.034812\n",
      "Train Epoch: 7 [54400/60032 (91%)]\tLoss: 0.021782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [55040/60032 (92%)]\tLoss: 0.044011\n",
      "Train Epoch: 7 [55680/60032 (93%)]\tLoss: 0.021235\n",
      "Train Epoch: 7 [56320/60032 (94%)]\tLoss: 0.083562\n",
      "Train Epoch: 7 [56960/60032 (95%)]\tLoss: 0.075774\n",
      "Train Epoch: 7 [57600/60032 (96%)]\tLoss: 0.177839\n",
      "Train Epoch: 7 [58240/60032 (97%)]\tLoss: 0.031464\n",
      "Train Epoch: 7 [58880/60032 (98%)]\tLoss: 0.072000\n",
      "Train Epoch: 7 [59520/60032 (99%)]\tLoss: 0.026675\n",
      "\n",
      "Test set: Average loss: 0.0444, Accuracy: 9861/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60032 (0%)]\tLoss: 0.057219\n",
      "Train Epoch: 8 [640/60032 (1%)]\tLoss: 0.003078\n",
      "Train Epoch: 8 [1280/60032 (2%)]\tLoss: 0.008518\n",
      "Train Epoch: 8 [1920/60032 (3%)]\tLoss: 0.036687\n",
      "Train Epoch: 8 [2560/60032 (4%)]\tLoss: 0.012121\n",
      "Train Epoch: 8 [3200/60032 (5%)]\tLoss: 0.095478\n",
      "Train Epoch: 8 [3840/60032 (6%)]\tLoss: 0.075754\n",
      "Train Epoch: 8 [4480/60032 (7%)]\tLoss: 0.036107\n",
      "Train Epoch: 8 [5120/60032 (9%)]\tLoss: 0.064524\n",
      "Train Epoch: 8 [5760/60032 (10%)]\tLoss: 0.078499\n",
      "Train Epoch: 8 [6400/60032 (11%)]\tLoss: 0.019512\n",
      "Train Epoch: 8 [7040/60032 (12%)]\tLoss: 0.073466\n",
      "Train Epoch: 8 [7680/60032 (13%)]\tLoss: 0.017923\n",
      "Train Epoch: 8 [8320/60032 (14%)]\tLoss: 0.069045\n",
      "Train Epoch: 8 [8960/60032 (15%)]\tLoss: 0.009038\n",
      "Train Epoch: 8 [9600/60032 (16%)]\tLoss: 0.011237\n",
      "Train Epoch: 8 [10240/60032 (17%)]\tLoss: 0.009303\n",
      "Train Epoch: 8 [10880/60032 (18%)]\tLoss: 0.143615\n",
      "Train Epoch: 8 [11520/60032 (19%)]\tLoss: 0.031519\n",
      "Train Epoch: 8 [12160/60032 (20%)]\tLoss: 0.033872\n",
      "Train Epoch: 8 [12800/60032 (21%)]\tLoss: 0.010239\n",
      "Train Epoch: 8 [13440/60032 (22%)]\tLoss: 0.136343\n",
      "Train Epoch: 8 [14080/60032 (23%)]\tLoss: 0.059478\n",
      "Train Epoch: 8 [14720/60032 (25%)]\tLoss: 0.023596\n",
      "Train Epoch: 8 [15360/60032 (26%)]\tLoss: 0.007915\n",
      "Train Epoch: 8 [16000/60032 (27%)]\tLoss: 0.007832\n",
      "Train Epoch: 8 [16640/60032 (28%)]\tLoss: 0.002629\n",
      "Train Epoch: 8 [17280/60032 (29%)]\tLoss: 0.031630\n",
      "Train Epoch: 8 [17920/60032 (30%)]\tLoss: 0.014195\n",
      "Train Epoch: 8 [18560/60032 (31%)]\tLoss: 0.044461\n",
      "Train Epoch: 8 [19200/60032 (32%)]\tLoss: 0.023987\n",
      "Train Epoch: 8 [19840/60032 (33%)]\tLoss: 0.112982\n",
      "Train Epoch: 8 [20480/60032 (34%)]\tLoss: 0.028499\n",
      "Train Epoch: 8 [21120/60032 (35%)]\tLoss: 0.002999\n",
      "Train Epoch: 8 [21760/60032 (36%)]\tLoss: 0.031287\n",
      "Train Epoch: 8 [22400/60032 (37%)]\tLoss: 0.026241\n",
      "Train Epoch: 8 [23040/60032 (38%)]\tLoss: 0.091724\n",
      "Train Epoch: 8 [23680/60032 (39%)]\tLoss: 0.016156\n",
      "Train Epoch: 8 [24320/60032 (41%)]\tLoss: 0.070003\n",
      "Train Epoch: 8 [24960/60032 (42%)]\tLoss: 0.046049\n",
      "Train Epoch: 8 [25600/60032 (43%)]\tLoss: 0.160345\n",
      "Train Epoch: 8 [26240/60032 (44%)]\tLoss: 0.059397\n",
      "Train Epoch: 8 [26880/60032 (45%)]\tLoss: 0.003004\n",
      "Train Epoch: 8 [27520/60032 (46%)]\tLoss: 0.051093\n",
      "Train Epoch: 8 [28160/60032 (47%)]\tLoss: 0.044635\n",
      "Train Epoch: 8 [28800/60032 (48%)]\tLoss: 0.002610\n",
      "Train Epoch: 8 [29440/60032 (49%)]\tLoss: 0.021712\n",
      "Train Epoch: 8 [30080/60032 (50%)]\tLoss: 0.033620\n",
      "Train Epoch: 8 [30720/60032 (51%)]\tLoss: 0.041339\n",
      "Train Epoch: 8 [31360/60032 (52%)]\tLoss: 0.024124\n",
      "Train Epoch: 8 [32000/60032 (53%)]\tLoss: 0.197290\n",
      "Train Epoch: 8 [32640/60032 (54%)]\tLoss: 0.057914\n",
      "Train Epoch: 8 [33280/60032 (55%)]\tLoss: 0.026103\n",
      "Train Epoch: 8 [33920/60032 (57%)]\tLoss: 0.063427\n",
      "Train Epoch: 8 [34560/60032 (58%)]\tLoss: 0.016219\n",
      "Train Epoch: 8 [35200/60032 (59%)]\tLoss: 0.039447\n",
      "Train Epoch: 8 [35840/60032 (60%)]\tLoss: 0.026637\n",
      "Train Epoch: 8 [36480/60032 (61%)]\tLoss: 0.031155\n",
      "Train Epoch: 8 [37120/60032 (62%)]\tLoss: 0.026735\n",
      "Train Epoch: 8 [37760/60032 (63%)]\tLoss: 0.044729\n",
      "Train Epoch: 8 [38400/60032 (64%)]\tLoss: 0.069133\n",
      "Train Epoch: 8 [39040/60032 (65%)]\tLoss: 0.008567\n",
      "Train Epoch: 8 [39680/60032 (66%)]\tLoss: 0.012539\n",
      "Train Epoch: 8 [40320/60032 (67%)]\tLoss: 0.045769\n",
      "Train Epoch: 8 [40960/60032 (68%)]\tLoss: 0.117818\n",
      "Train Epoch: 8 [41600/60032 (69%)]\tLoss: 0.039776\n",
      "Train Epoch: 8 [42240/60032 (70%)]\tLoss: 0.045896\n",
      "Train Epoch: 8 [42880/60032 (71%)]\tLoss: 0.002212\n",
      "Train Epoch: 8 [43520/60032 (72%)]\tLoss: 0.050312\n",
      "Train Epoch: 8 [44160/60032 (74%)]\tLoss: 0.019903\n",
      "Train Epoch: 8 [44800/60032 (75%)]\tLoss: 0.146815\n",
      "Train Epoch: 8 [45440/60032 (76%)]\tLoss: 0.019701\n",
      "Train Epoch: 8 [46080/60032 (77%)]\tLoss: 0.055335\n",
      "Train Epoch: 8 [46720/60032 (78%)]\tLoss: 0.147488\n",
      "Train Epoch: 8 [47360/60032 (79%)]\tLoss: 0.007613\n",
      "Train Epoch: 8 [48000/60032 (80%)]\tLoss: 0.028862\n",
      "Train Epoch: 8 [48640/60032 (81%)]\tLoss: 0.114862\n",
      "Train Epoch: 8 [49280/60032 (82%)]\tLoss: 0.004458\n",
      "Train Epoch: 8 [49920/60032 (83%)]\tLoss: 0.014832\n",
      "Train Epoch: 8 [50560/60032 (84%)]\tLoss: 0.044349\n",
      "Train Epoch: 8 [51200/60032 (85%)]\tLoss: 0.022774\n",
      "Train Epoch: 8 [51840/60032 (86%)]\tLoss: 0.041733\n",
      "Train Epoch: 8 [52480/60032 (87%)]\tLoss: 0.064445\n",
      "Train Epoch: 8 [53120/60032 (88%)]\tLoss: 0.003769\n",
      "Train Epoch: 8 [53760/60032 (90%)]\tLoss: 0.038328\n",
      "Train Epoch: 8 [54400/60032 (91%)]\tLoss: 0.011603\n",
      "Train Epoch: 8 [55040/60032 (92%)]\tLoss: 0.019816\n",
      "Train Epoch: 8 [55680/60032 (93%)]\tLoss: 0.010147\n",
      "Train Epoch: 8 [56320/60032 (94%)]\tLoss: 0.034943\n",
      "Train Epoch: 8 [56960/60032 (95%)]\tLoss: 0.004913\n",
      "Train Epoch: 8 [57600/60032 (96%)]\tLoss: 0.083296\n",
      "Train Epoch: 8 [58240/60032 (97%)]\tLoss: 0.007382\n",
      "Train Epoch: 8 [58880/60032 (98%)]\tLoss: 0.013532\n",
      "Train Epoch: 8 [59520/60032 (99%)]\tLoss: 0.138568\n",
      "\n",
      "Test set: Average loss: 0.0363, Accuracy: 9885/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60032 (0%)]\tLoss: 0.005201\n",
      "Train Epoch: 9 [640/60032 (1%)]\tLoss: 0.084526\n",
      "Train Epoch: 9 [1280/60032 (2%)]\tLoss: 0.061451\n",
      "Train Epoch: 9 [1920/60032 (3%)]\tLoss: 0.011400\n",
      "Train Epoch: 9 [2560/60032 (4%)]\tLoss: 0.094555\n",
      "Train Epoch: 9 [3200/60032 (5%)]\tLoss: 0.013569\n",
      "Train Epoch: 9 [3840/60032 (6%)]\tLoss: 0.019486\n",
      "Train Epoch: 9 [4480/60032 (7%)]\tLoss: 0.011726\n",
      "Train Epoch: 9 [5120/60032 (9%)]\tLoss: 0.013290\n",
      "Train Epoch: 9 [5760/60032 (10%)]\tLoss: 0.010031\n",
      "Train Epoch: 9 [6400/60032 (11%)]\tLoss: 0.009856\n",
      "Train Epoch: 9 [7040/60032 (12%)]\tLoss: 0.034052\n",
      "Train Epoch: 9 [7680/60032 (13%)]\tLoss: 0.062572\n",
      "Train Epoch: 9 [8320/60032 (14%)]\tLoss: 0.011877\n",
      "Train Epoch: 9 [8960/60032 (15%)]\tLoss: 0.011535\n",
      "Train Epoch: 9 [9600/60032 (16%)]\tLoss: 0.018038\n",
      "Train Epoch: 9 [10240/60032 (17%)]\tLoss: 0.014102\n",
      "Train Epoch: 9 [10880/60032 (18%)]\tLoss: 0.038503\n",
      "Train Epoch: 9 [11520/60032 (19%)]\tLoss: 0.071947\n",
      "Train Epoch: 9 [12160/60032 (20%)]\tLoss: 0.139651\n",
      "Train Epoch: 9 [12800/60032 (21%)]\tLoss: 0.028413\n",
      "Train Epoch: 9 [13440/60032 (22%)]\tLoss: 0.007067\n",
      "Train Epoch: 9 [14080/60032 (23%)]\tLoss: 0.014811\n",
      "Train Epoch: 9 [14720/60032 (25%)]\tLoss: 0.032960\n",
      "Train Epoch: 9 [15360/60032 (26%)]\tLoss: 0.022676\n",
      "Train Epoch: 9 [16000/60032 (27%)]\tLoss: 0.010070\n",
      "Train Epoch: 9 [16640/60032 (28%)]\tLoss: 0.075636\n",
      "Train Epoch: 9 [17280/60032 (29%)]\tLoss: 0.039747\n",
      "Train Epoch: 9 [17920/60032 (30%)]\tLoss: 0.096968\n",
      "Train Epoch: 9 [18560/60032 (31%)]\tLoss: 0.055811\n",
      "Train Epoch: 9 [19200/60032 (32%)]\tLoss: 0.023607\n",
      "Train Epoch: 9 [19840/60032 (33%)]\tLoss: 0.001816\n",
      "Train Epoch: 9 [20480/60032 (34%)]\tLoss: 0.012791\n",
      "Train Epoch: 9 [21120/60032 (35%)]\tLoss: 0.007072\n",
      "Train Epoch: 9 [21760/60032 (36%)]\tLoss: 0.009383\n",
      "Train Epoch: 9 [22400/60032 (37%)]\tLoss: 0.071221\n",
      "Train Epoch: 9 [23040/60032 (38%)]\tLoss: 0.071312\n",
      "Train Epoch: 9 [23680/60032 (39%)]\tLoss: 0.016690\n",
      "Train Epoch: 9 [24320/60032 (41%)]\tLoss: 0.010223\n",
      "Train Epoch: 9 [24960/60032 (42%)]\tLoss: 0.030601\n",
      "Train Epoch: 9 [25600/60032 (43%)]\tLoss: 0.032997\n",
      "Train Epoch: 9 [26240/60032 (44%)]\tLoss: 0.024813\n",
      "Train Epoch: 9 [26880/60032 (45%)]\tLoss: 0.033880\n",
      "Train Epoch: 9 [27520/60032 (46%)]\tLoss: 0.067418\n",
      "Train Epoch: 9 [28160/60032 (47%)]\tLoss: 0.025995\n",
      "Train Epoch: 9 [28800/60032 (48%)]\tLoss: 0.125716\n",
      "Train Epoch: 9 [29440/60032 (49%)]\tLoss: 0.016147\n",
      "Train Epoch: 9 [30080/60032 (50%)]\tLoss: 0.003161\n",
      "Train Epoch: 9 [30720/60032 (51%)]\tLoss: 0.041030\n",
      "Train Epoch: 9 [31360/60032 (52%)]\tLoss: 0.009197\n",
      "Train Epoch: 9 [32000/60032 (53%)]\tLoss: 0.002736\n",
      "Train Epoch: 9 [32640/60032 (54%)]\tLoss: 0.050677\n",
      "Train Epoch: 9 [33280/60032 (55%)]\tLoss: 0.096314\n",
      "Train Epoch: 9 [33920/60032 (57%)]\tLoss: 0.011857\n",
      "Train Epoch: 9 [34560/60032 (58%)]\tLoss: 0.027661\n",
      "Train Epoch: 9 [35200/60032 (59%)]\tLoss: 0.004575\n",
      "Train Epoch: 9 [35840/60032 (60%)]\tLoss: 0.029942\n",
      "Train Epoch: 9 [36480/60032 (61%)]\tLoss: 0.035032\n",
      "Train Epoch: 9 [37120/60032 (62%)]\tLoss: 0.043196\n",
      "Train Epoch: 9 [37760/60032 (63%)]\tLoss: 0.007628\n",
      "Train Epoch: 9 [38400/60032 (64%)]\tLoss: 0.010769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [39040/60032 (65%)]\tLoss: 0.088517\n",
      "Train Epoch: 9 [39680/60032 (66%)]\tLoss: 0.005169\n",
      "Train Epoch: 9 [40320/60032 (67%)]\tLoss: 0.018577\n",
      "Train Epoch: 9 [40960/60032 (68%)]\tLoss: 0.021493\n",
      "Train Epoch: 9 [41600/60032 (69%)]\tLoss: 0.007582\n",
      "Train Epoch: 9 [42240/60032 (70%)]\tLoss: 0.031127\n",
      "Train Epoch: 9 [42880/60032 (71%)]\tLoss: 0.022230\n",
      "Train Epoch: 9 [43520/60032 (72%)]\tLoss: 0.035726\n",
      "Train Epoch: 9 [44160/60032 (74%)]\tLoss: 0.004209\n",
      "Train Epoch: 9 [44800/60032 (75%)]\tLoss: 0.005635\n",
      "Train Epoch: 9 [45440/60032 (76%)]\tLoss: 0.030155\n",
      "Train Epoch: 9 [46080/60032 (77%)]\tLoss: 0.047122\n",
      "Train Epoch: 9 [46720/60032 (78%)]\tLoss: 0.010066\n",
      "Train Epoch: 9 [47360/60032 (79%)]\tLoss: 0.152536\n",
      "Train Epoch: 9 [48000/60032 (80%)]\tLoss: 0.013908\n",
      "Train Epoch: 9 [48640/60032 (81%)]\tLoss: 0.027193\n",
      "Train Epoch: 9 [49280/60032 (82%)]\tLoss: 0.034739\n",
      "Train Epoch: 9 [49920/60032 (83%)]\tLoss: 0.006287\n",
      "Train Epoch: 9 [50560/60032 (84%)]\tLoss: 0.011080\n",
      "Train Epoch: 9 [51200/60032 (85%)]\tLoss: 0.015259\n",
      "Train Epoch: 9 [51840/60032 (86%)]\tLoss: 0.072330\n",
      "Train Epoch: 9 [52480/60032 (87%)]\tLoss: 0.021602\n",
      "Train Epoch: 9 [53120/60032 (88%)]\tLoss: 0.022658\n",
      "Train Epoch: 9 [53760/60032 (90%)]\tLoss: 0.019059\n",
      "Train Epoch: 9 [54400/60032 (91%)]\tLoss: 0.015700\n",
      "Train Epoch: 9 [55040/60032 (92%)]\tLoss: 0.013213\n",
      "Train Epoch: 9 [55680/60032 (93%)]\tLoss: 0.006806\n",
      "Train Epoch: 9 [56320/60032 (94%)]\tLoss: 0.074057\n",
      "Train Epoch: 9 [56960/60032 (95%)]\tLoss: 0.083273\n",
      "Train Epoch: 9 [57600/60032 (96%)]\tLoss: 0.011113\n",
      "Train Epoch: 9 [58240/60032 (97%)]\tLoss: 0.006564\n",
      "Train Epoch: 9 [58880/60032 (98%)]\tLoss: 0.040048\n",
      "Train Epoch: 9 [59520/60032 (99%)]\tLoss: 0.006982\n",
      "\n",
      "Test set: Average loss: 0.0345, Accuracy: 9888/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60032 (0%)]\tLoss: 0.004195\n",
      "Train Epoch: 10 [640/60032 (1%)]\tLoss: 0.008745\n",
      "Train Epoch: 10 [1280/60032 (2%)]\tLoss: 0.011576\n",
      "Train Epoch: 10 [1920/60032 (3%)]\tLoss: 0.030435\n",
      "Train Epoch: 10 [2560/60032 (4%)]\tLoss: 0.004746\n",
      "Train Epoch: 10 [3200/60032 (5%)]\tLoss: 0.009053\n",
      "Train Epoch: 10 [3840/60032 (6%)]\tLoss: 0.030438\n",
      "Train Epoch: 10 [4480/60032 (7%)]\tLoss: 0.008765\n",
      "Train Epoch: 10 [5120/60032 (9%)]\tLoss: 0.019785\n",
      "Train Epoch: 10 [5760/60032 (10%)]\tLoss: 0.002012\n",
      "Train Epoch: 10 [6400/60032 (11%)]\tLoss: 0.055273\n",
      "Train Epoch: 10 [7040/60032 (12%)]\tLoss: 0.007018\n",
      "Train Epoch: 10 [7680/60032 (13%)]\tLoss: 0.088347\n",
      "Train Epoch: 10 [8320/60032 (14%)]\tLoss: 0.047575\n",
      "Train Epoch: 10 [8960/60032 (15%)]\tLoss: 0.031517\n",
      "Train Epoch: 10 [9600/60032 (16%)]\tLoss: 0.032788\n",
      "Train Epoch: 10 [10240/60032 (17%)]\tLoss: 0.037372\n",
      "Train Epoch: 10 [10880/60032 (18%)]\tLoss: 0.005101\n",
      "Train Epoch: 10 [11520/60032 (19%)]\tLoss: 0.035940\n",
      "Train Epoch: 10 [12160/60032 (20%)]\tLoss: 0.007406\n",
      "Train Epoch: 10 [12800/60032 (21%)]\tLoss: 0.002354\n",
      "Train Epoch: 10 [13440/60032 (22%)]\tLoss: 0.009191\n",
      "Train Epoch: 10 [14080/60032 (23%)]\tLoss: 0.017855\n",
      "Train Epoch: 10 [14720/60032 (25%)]\tLoss: 0.028823\n",
      "Train Epoch: 10 [15360/60032 (26%)]\tLoss: 0.002591\n",
      "Train Epoch: 10 [16000/60032 (27%)]\tLoss: 0.057401\n",
      "Train Epoch: 10 [16640/60032 (28%)]\tLoss: 0.101467\n",
      "Train Epoch: 10 [17280/60032 (29%)]\tLoss: 0.035925\n",
      "Train Epoch: 10 [17920/60032 (30%)]\tLoss: 0.014235\n",
      "Train Epoch: 10 [18560/60032 (31%)]\tLoss: 0.017406\n",
      "Train Epoch: 10 [19200/60032 (32%)]\tLoss: 0.146277\n",
      "Train Epoch: 10 [19840/60032 (33%)]\tLoss: 0.023269\n",
      "Train Epoch: 10 [20480/60032 (34%)]\tLoss: 0.006259\n",
      "Train Epoch: 10 [21120/60032 (35%)]\tLoss: 0.033371\n",
      "Train Epoch: 10 [21760/60032 (36%)]\tLoss: 0.018935\n",
      "Train Epoch: 10 [22400/60032 (37%)]\tLoss: 0.003462\n",
      "Train Epoch: 10 [23040/60032 (38%)]\tLoss: 0.191908\n",
      "Train Epoch: 10 [23680/60032 (39%)]\tLoss: 0.017181\n",
      "Train Epoch: 10 [24320/60032 (41%)]\tLoss: 0.015431\n",
      "Train Epoch: 10 [24960/60032 (42%)]\tLoss: 0.009658\n",
      "Train Epoch: 10 [25600/60032 (43%)]\tLoss: 0.023228\n",
      "Train Epoch: 10 [26240/60032 (44%)]\tLoss: 0.010427\n",
      "Train Epoch: 10 [26880/60032 (45%)]\tLoss: 0.012248\n",
      "Train Epoch: 10 [27520/60032 (46%)]\tLoss: 0.007247\n",
      "Train Epoch: 10 [28160/60032 (47%)]\tLoss: 0.028980\n",
      "Train Epoch: 10 [28800/60032 (48%)]\tLoss: 0.008800\n",
      "Train Epoch: 10 [29440/60032 (49%)]\tLoss: 0.011604\n",
      "Train Epoch: 10 [30080/60032 (50%)]\tLoss: 0.077276\n",
      "Train Epoch: 10 [30720/60032 (51%)]\tLoss: 0.014052\n",
      "Train Epoch: 10 [31360/60032 (52%)]\tLoss: 0.013256\n",
      "Train Epoch: 10 [32000/60032 (53%)]\tLoss: 0.022790\n",
      "Train Epoch: 10 [32640/60032 (54%)]\tLoss: 0.026510\n",
      "Train Epoch: 10 [33280/60032 (55%)]\tLoss: 0.097713\n",
      "Train Epoch: 10 [33920/60032 (57%)]\tLoss: 0.010731\n",
      "Train Epoch: 10 [34560/60032 (58%)]\tLoss: 0.032814\n",
      "Train Epoch: 10 [35200/60032 (59%)]\tLoss: 0.048252\n",
      "Train Epoch: 10 [35840/60032 (60%)]\tLoss: 0.005564\n",
      "Train Epoch: 10 [36480/60032 (61%)]\tLoss: 0.017492\n",
      "Train Epoch: 10 [37120/60032 (62%)]\tLoss: 0.009913\n",
      "Train Epoch: 10 [37760/60032 (63%)]\tLoss: 0.114096\n",
      "Train Epoch: 10 [38400/60032 (64%)]\tLoss: 0.027583\n",
      "Train Epoch: 10 [39040/60032 (65%)]\tLoss: 0.043505\n",
      "Train Epoch: 10 [39680/60032 (66%)]\tLoss: 0.030766\n",
      "Train Epoch: 10 [40320/60032 (67%)]\tLoss: 0.072976\n",
      "Train Epoch: 10 [40960/60032 (68%)]\tLoss: 0.085153\n",
      "Train Epoch: 10 [41600/60032 (69%)]\tLoss: 0.060548\n",
      "Train Epoch: 10 [42240/60032 (70%)]\tLoss: 0.013657\n",
      "Train Epoch: 10 [42880/60032 (71%)]\tLoss: 0.037631\n",
      "Train Epoch: 10 [43520/60032 (72%)]\tLoss: 0.016243\n",
      "Train Epoch: 10 [44160/60032 (74%)]\tLoss: 0.005125\n",
      "Train Epoch: 10 [44800/60032 (75%)]\tLoss: 0.068803\n",
      "Train Epoch: 10 [45440/60032 (76%)]\tLoss: 0.016163\n",
      "Train Epoch: 10 [46080/60032 (77%)]\tLoss: 0.004874\n",
      "Train Epoch: 10 [46720/60032 (78%)]\tLoss: 0.168885\n",
      "Train Epoch: 10 [47360/60032 (79%)]\tLoss: 0.008019\n",
      "Train Epoch: 10 [48000/60032 (80%)]\tLoss: 0.075777\n",
      "Train Epoch: 10 [48640/60032 (81%)]\tLoss: 0.010419\n",
      "Train Epoch: 10 [49280/60032 (82%)]\tLoss: 0.067886\n",
      "Train Epoch: 10 [49920/60032 (83%)]\tLoss: 0.042780\n",
      "Train Epoch: 10 [50560/60032 (84%)]\tLoss: 0.191826\n",
      "Train Epoch: 10 [51200/60032 (85%)]\tLoss: 0.008612\n",
      "Train Epoch: 10 [51840/60032 (86%)]\tLoss: 0.004117\n",
      "Train Epoch: 10 [52480/60032 (87%)]\tLoss: 0.009461\n",
      "Train Epoch: 10 [53120/60032 (88%)]\tLoss: 0.018364\n",
      "Train Epoch: 10 [53760/60032 (90%)]\tLoss: 0.099997\n",
      "Train Epoch: 10 [54400/60032 (91%)]\tLoss: 0.063124\n",
      "Train Epoch: 10 [55040/60032 (92%)]\tLoss: 0.051941\n",
      "Train Epoch: 10 [55680/60032 (93%)]\tLoss: 0.003073\n",
      "Train Epoch: 10 [56320/60032 (94%)]\tLoss: 0.026992\n",
      "Train Epoch: 10 [56960/60032 (95%)]\tLoss: 0.034911\n",
      "Train Epoch: 10 [57600/60032 (96%)]\tLoss: 0.013454\n",
      "Train Epoch: 10 [58240/60032 (97%)]\tLoss: 0.047807\n",
      "Train Epoch: 10 [58880/60032 (98%)]\tLoss: 0.108150\n",
      "Train Epoch: 10 [59520/60032 (99%)]\tLoss: 0.007507\n",
      "\n",
      "Test set: Average loss: 0.0381, Accuracy: 9869/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(torch)  \n",
    "bob = sy.VirtualWorker(hook, id = \"bob\") \n",
    "alice = sy.VirtualWorker(hook, id = \"alice\")\n",
    "args = ts.Arguments()\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST('~/workspace/data', train = True, download = True,\n",
    "                   transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "    .federate((bob, alice)), batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('~/workspace/data', train = False, \n",
    "                   transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                   transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size = args.test_batch_size, shuffle=True, **kwargs)\n",
    "    \n",
    "model = ts.Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    ts.train(args, model, device, federated_train_loader, optimizer, epoch)\n",
    "    ts.test(args, model, device, test_loader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\") \n",
    "    # https://michhar.github.io/convert-pytorch-onnx/\n",
    "    dummy_input = torch.randn(1000,1,28,28) #based on test_loader fom mnist_model_torchsyft\n",
    "    torch.onnx.export(model, dummy_input, \"../models/mnist_cnn.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model And Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T17:40:54.056643Z",
     "start_time": "2019-06-30T17:40:54.004760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ld = Net().to(device)\n",
    "model_ld.load_state_dict(torch.load(\"../models/mnist_cnn.pt\"))\n",
    "model_ld.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-30T19:47:04.173159Z",
     "start_time": "2019-06-30T19:47:03.688469Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "y_pred = model_ld(images)\n",
    "\n",
    "print(y_pred[0].data.cpu().numpy().argmax(axis = 0))\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
